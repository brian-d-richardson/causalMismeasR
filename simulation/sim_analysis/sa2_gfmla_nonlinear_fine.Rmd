---
title: "Simulation 2: g-formula with nonlinear MSM and fine grid"
author: "Brian Richardson"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output:
  html_document:
    code_folding: hide
---

```{r message = F, warning = F}

rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(kableExtra)
library(devtools)
load_all()

```

```{r warning = F, message = F}

# load simulation results from each of 10 clusters
setwd(dirname(getwd()))
sim.out.list <- lapply(
  X = 0:9,
  FUN = function(clust) {
    cbind(clust,
          read.csv(paste0("sim_data/sim2_gfmla_nonlinear_fine/sd",
                          clust, ".csv")))
  })


# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)

# true estimands
g <- c(0, 0.25, 0.5, -0.5, 1)          # outcome model parameters
a <- seq(-1, 2, length = 20)           # exposure value of interest
EYa.true <- g[1] + 0.5*g[5] + a*g[2] + a^2*g[3] + a^3*g[4]

# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare))

# make long data frame
sim.out.long <- sim.out %>% 
  dplyr::select(!starts_with("a")) %>% 
  pivot_longer(cols = starts_with("OG") | starts_with("NG") |
                      starts_with("RG") | starts_with("SG") | 
                      starts_with("CG"), 
               names_to = "method.aa",
               values_to = "val") %>% 
    mutate(method = factor(substr(method.aa, 1, 2),
                           levels = c("OG", "NG", "RG", "SG", "CG"),
                           labels = c("Oracle G-Formula",
                                      "Naive G-Formula",
                                      "Reg. Cal. G-Formula",
                                      "SIMEX G-Formula",
                                      "CS G-Formula")),
           aa = as.numeric(gsub("[.]", "", substr(method.aa, 4, 5))),
           a = a[aa],
           EYa.true = EYa.true[aa]) %>% 
  dplyr::select(-method.aa)

# make summary data frame
sim.out.summary <- sim.out.long %>% 
  group_by(n, vare, B, method, a) %>% 
  summarise(bias = mean(val - EYa.true),
            se = sd(val) / sqrt(n.rep),
            bias.lower = bias - qnorm(0.975) * se,
            bias.upper = bias + qnorm(0.975) * se)

```

The goal of this program is to evaluate the CS G-Formula estimator with a nonlinear outcome model and for a coarse grid of exposure values.

## Setup

Consider the following setup:

* single confounder $L_1 \sim U(0,1)$,
* univariate continuous exposure $A$ with $A|L \sim N(L,)$,
* mismeasured exposure $A^* = A + \epsilon$, where $\epsilon \sim N(0, 0.09)$,
* normal outcome $Y$ with $Y|A,L \sim N(0.25A + 0.5A^2 - 0.5A^3 + L, 0.16)$.

This data generating process leads to a mean potential outcome at $a$ of $\textrm{E}\{Y(a)\} = 0.5 + 0.25a + 0.5a^2 - 0.5a^3$.

The estimand of interest in these simulations is the dose response curve $\{\textrm{E}[Y(a)] : a \in \mathcal{A}\}$.

## Setup

Consider the following setup:

* single confounder $L_1 \sim U(0,1)$,
* univariate continuous exposure $A$ with $A|L \sim N(L,)$,
* mismeasured exposure $A^* = A + \epsilon$, where $\epsilon \sim N(0, 0.09)$,
* normal outcome $Y$ with $Y|A,L \sim N(0 + 0.25A, 0.5A^2, -0.5^2 + L, 0.16)$.

This data generating process leads to a mean potential outcome at $a$ of $\textrm{E}\{Y(a)\} = 0.5 + 0.25a + 0.5a^2 - 0.5a^3$.

The estimand of interest in these simulations is the dose response curve $\{\textrm{E}[Y(a)] : a \in \mathcal{A}\}$.

## Methods

In these simulations, we compare five methods:

1) Oracle G-Formula
2) Naive G-Formula
3) Regression Calibration G-Formula
4) SIMEX G-Formula
5) CS G-Formula

The oracle method uses the true exposure values $A$, which are not observed in practice. The naive method treats $A^*$ as $A$, assuming there is no measurement error. Regression calibration replaces $A^*$ with an approximation of $\textrm{E}(A|A^*,L)$. SIMEX uses simulated data with a sequence of additional measurement error to extrapolate backwards to estimate the dose response curve with no measurement error. The CS method uses the Monte-Carlo corrected score versions of the estimating functions.

## Results

We first check for simulations with errors.

```{r message = F}

# summarize proportion of missing data by setting
sim.out.long %>% 
  filter(aa == 1) %>% 
  group_by(method, n, B, vare) %>% 
  summarise(prop.error = mean(is.na(val))) %>% 
  filter(prop.error > 0) %>% 
  ungroup()

```

```{r}

# extract simulation parameters
n <- unique(sim.out$n)

# make labels for plots
method.labs <- c("Oracle G-Formula",
                 "Naive G-Formula",
                 "Reg. Cal. G-Formula",
                 "SIMEX G-Formula",
                 "CS G-Formula")

names(method.labs) <- c("OG", "NG", "RG", "SG", "CG")

n.labs <- paste0("n = ", n)
names(n.labs) <- n

a.labs <- paste0("a = ", a)
names(a.labs) <- a

# colorblind friendly pallette
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')

```

```{r}

p <- sim.out.summary %>% 
  ggplot(
    aes(x = a,
        y = bias)) +
  geom_point() +
  geom_line() +
  facet_grid(n ~ method,
             labeller = labeller(n = function(x) paste0("n = ", x))) +
  theme_bw() +
  theme(legend.position = c(0.2, 0.3)) +
  labs(color = "Method",
       shape = "Method",
       fill = "Method",
       y = "Bias") +
  scale_y_continuous(
    limits = 0.18 * c(-1, 1),
    oob = scales::rescale_none
  )

p

```

```{r warning = F}

# save plot
setwd(dirname(getwd()))
ggsave("sim_figures/sim2_gfmla_nonlinear_fine.png",
       width = 7,
       height = 4,
       dpi = 300)

```

