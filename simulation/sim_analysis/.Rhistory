fill = method,
color = method)) +
geom_boxplot() +
stat_summary(fun = mean,
geom = "point",
shape = 8,
size = 2,
orientation = "x",
show.legend = F) +
geom_hline(aes(yintercept = g.true),
linetype = "dashed",
color = "orange") +
facet_wrap(~pi.cc,
scales = "free_x",
#scales = "free",
labeller = labeller(param = param.labs), nrow = 1) +
labs(y = "Parameter Estimate",
fill = "Method",
color = "Method") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
legend.position = "bottom") +
scale_fill_manual(values = pal_light) +
scale_color_manual(values = pal_dark)
if (title) {
plot <- plot +
ggtitle(paste0("Empirical Distribution of Parameter Estimates"),
subtitle = paste0(n.rep, " simulations per setting"))
}
return(plot)
}
make.plot()
tbl <- sim.out.long %>%
mutate(Param = paste0("$\\gamma_", as.numeric(param) - 1, "$")) %>%
group_by(n, pi.cc, method) %>%
summarise(bias = 100 * mean(ghat - g.true),
emp.se = 100 * sd(ghat),
est.se = 100 * mean(stde),
ci.cov = 100 * mean(ci.cov),
bcest.se = 100 * mean(bste),
bcci.cov = 100 * mean(bcci.cov))
kbl <- tbl %>%
kable(format = "latex",
digits = c(0, 0, 0,
1, 1,
1, 1,
1, 1),
align = c(rep("c", 3 + 2),
rep("r", 4)),
booktabs = TRUE,
linesep = c("", "", "\\addlinespace"),
escape = FALSE,
col.names = c("n", "pi.cc", "Method",
"Bias", "ESE",
"ASE", "Cov",
"ASE", "Cov")) %>%
add_header_above(c(" " = 5 + 2,
"UC" = 2,
"BC" = 2)) %>%
kable_styling("striped") %>%
row_spec(row = 0, bold = TRUE)
print(kbl)
View(tbl)
library(MASS); library(devtools); load_all();
n = 2000; vare = 0.01; B = 80; pi.cc = 0.5; seed = 1;
mc.seed <- 123                                # MCCS seed
inv.link <- inv.ident                         # inverse link
d.inv.link <- d.inv.ident                     # deriv of inv link
g <- c(0.35, 0.15, 0.25, 0.2, 0.05, 0.1)      # outcome model parameters
formula <- "~A*L1 + A*L2"                     # outcome model formula
ps.formula <- "~L1 + L2"                      # propensity score model formula
ipw.formula <- "~A"                           # ipw.formula
set.seed(seed)
cov.e <- vare
L1 <- rbinom(n, 1, 0.5)                                  # confounder 1
L2 <- rnorm(n, 0, 0.16)                                  # confounder 2
EA <- 0.1 - 0.1*L1 + 0.3*L2                              # E(A|L)
A <- rnorm(n, EA, sqrt(0.04))                            # exposure
Astar <- A + rnorm(n, 0, sqrt(cov.e))                    # mismeasured A
var(A) / var(Astar)
n = 10^6
vare = .02
mc.seed <- 123                                # MCCS seed
inv.link <- inv.ident                         # inverse link
d.inv.link <- d.inv.ident                     # deriv of inv link
g <- c(0.35, 0.15, 0.25, 0.2, 0.05, 0.1)      # outcome model parameters
formula <- "~A*L1 + A*L2"                     # outcome model formula
ps.formula <- "~L1 + L2"                      # propensity score model formula
ipw.formula <- "~A"                           # ipw.formula
# simulate data -----------------------------------------------------------
set.seed(seed)
cov.e <- vare
L1 <- rbinom(n, 1, 0.5)                                  # confounder 1
L2 <- rnorm(n, 0, 0.16)                                  # confounder 2
EA <- 0.1 - 0.1*L1 + 0.3*L2                              # E(A|L)
A <- rnorm(n, EA, sqrt(0.04))                            # exposure
Astar <- A + rnorm(n, 0, sqrt(cov.e))                    # mismeasured A
var(A) / var(Astar)
knitr::opts_chunk$set(echo = TRUE)
## install the package
devtools::install_github(repo = "brian-d-richardson/mismex",
ref = "main")
rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(kableExtra)
# load simulation results from each of 10 clusters
setwd(dirname(getwd()))
sim.out.list <- lapply(
X = 0:9,
FUN = function(clust) {
cbind(clust,
read.csv(paste0("sim_data/sim10_dr_cc/sd",
clust, ".csv")))
})
# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)
# true MSM parameters
g <- 0.175
# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare, pi.cc))
# make long data frame
sim.out.long <- sim.out %>%
pivot_longer(cols = starts_with("ghat") |
starts_with("stde") |
starts_with("bste"),
names_to = "method.param",
values_to = "val") %>%
mutate(method = factor(substr(method.param, 6, 6),
levels = c("O", "N", "C"),
labels = c("Oracle DR",
"Naive DR",
"DR CS")),
param = factor(substr(method.param, 8, 8)),
name = factor(substr(method.param, 1, 4)),
g.true = g[param]) %>%
dplyr::select(-method.param) %>%
group_by(clust, n, B, vare, method, pi.cc, param, name) %>%
mutate(id = row_number()) %>%
pivot_wider(names_from = name,
values_from = val,
id_cols = c(clust, n, B, vare, pi.cc, method,
param, g.true, id)) %>%
mutate(ci.lower = ghat - qnorm(0.975) * stde,
ci.upper = ghat + qnorm(0.975) * stde,
ci.cov = g.true >= ci.lower & g.true <= ci.upper,
bcci.lower = ghat - qnorm(0.975) * bste,
bcci.upper = ghat + qnorm(0.975) * bste,
bcci.cov = g.true >= bcci.lower & g.true <= bcci.upper)
# summarize proportion of missing data by setting
sim.out.long %>%
filter(param == 1) %>%
group_by(method, n, vare, B, pi.cc) %>%
summarise(prop.error = mean(is.na(ghat))) %>%
filter(prop.error > 0) %>%
ungroup()
# extract simulation parameters
n <- unique(sim.out$n)
B <- unique(sim.out$B)
vare <- unique(sim.out$vare)
# make labels for plots
n.labs <- paste0("n = ", n)
names(n.labs) <- n
B.labs <- paste0("B = ", B)
names(B.labs) <- B
vare.labs <- paste0("var(e) = ", vare)
names(vare.labs) <- vare
n.labs <- paste0("n = ", n)
names(n.labs) <- n
param.labs <- paste0("\u03b3", c("0", "1", "2", "3"))
names(param.labs) <- 1:4
# colorblind friendly pallette
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')
# create plots
make.plot <- function(title = T, y.lim = Inf, vare. = vare) {
plot <- sim.out.long %>%
filter(abs(ghat - g.true) < y.lim,
vare %in% vare.) %>%
ggplot(
aes(x = pi.cc,
y = ghat,
fill = method,
color = method)) +
geom_boxplot() +
stat_summary(fun = mean,
geom = "point",
shape = 8,
size = 2,
orientation = "x",
show.legend = F) +
geom_hline(aes(yintercept = g.true),
linetype = "dashed",
color = "orange") +
facet_wrap(~pi.cc,
scales = "free_x",
#scales = "free",
labeller = labeller(param = param.labs), nrow = 1) +
labs(y = "Parameter Estimate",
fill = "Method",
color = "Method") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
legend.position = "bottom") +
scale_fill_manual(values = pal_light) +
scale_color_manual(values = pal_dark)
if (title) {
plot <- plot +
ggtitle(paste0("Empirical Distribution of Parameter Estimates"),
subtitle = paste0(n.rep, " simulations per setting"))
}
return(plot)
}
make.plot()
knitr::opts_chunk$set(echo = TRUE)
## install the package
devtools::install_github(repo = "brian-d-richardson/mismex",
ref = "main")
## load the package
library(mismex)
library(devtools);
## load additional packages
library(MASS)
library(dplyr)
library(tidyverse)
library(ggplot2)
## load the package
library(mismex)
library(devtools);
## load additional packages
library(MASS)
library(dplyr)
library(tidyverse)
library(ggplot2)
## load the package
library(mismex)
library(devtools);
## load additional packages
library(MASS)
library(dplyr)
library(tidyverse)
library(ggplot2)
## define parameters
n = 2000                                  # sample size
seed = 1                                  # random number seed
mc.seed <- 123                            # MCCS seed
cov.e <- 0.36                             # var(epsilon)
inv.link <- inv.ident                     # inverse link
d.inv.link <- d.inv.ident                 # derivative of inverse link
g <- c(1.5, 0.7, 0.9, -0.6, -0.7, 0.4)    # outcome model parameters
formula <- "~A*L1 + A*L2"                 # outcome model formula
ps.formula <- "~L1 + L2"                  # propensity score model formula
ipw.formula <- "~A"                       # MSM formula
## generate data
set.seed(seed)
L1 <- rbinom(n, 1, 0.5)                                  # confounder 1
L2 <- rnorm(n, 1, sqrt(0.5))                             # confounder 2
A <- rnorm(n, 2 + 0.9*L1 - 0.6*L2, sqrt(1.1))            # exposure
a <- seq(min(A), max(A), length = 4)                     # grid of exposures
EY <- inv.link(model.matrix(as.formula(formula)) %*% g)  # mean of outcome
Y <- rnorm(n, EY, sqrt(0.16))                            # outcome
Astar <- A + rnorm(n, 0, sqrt(cov.e))                    # mismeasured A
datstar <- data.frame(Y, A = Astar, L1, L2)              # mismeasured data
head(datstar, 5)
## g-formula arguments
gfmla.args <- list(formula = formula,
inv.link = inv.link,
d.inv.link = d.inv.link)
## naive estimator
gfmla.naive <- fit.glm(data = datstar,
args = gfmla.args,
return.var = F)$est
## assess MCCS estimating function over grid of B values
gfmla.B.tuning <- tune.B(
get.psi = get.psi.glm,
data = datstar,
cov.e = cov.e,
BB = seq(1, 50, by = 2),
args = gfmla.args,
mc.seed = 123)
gfmla.B.tuning$plot
## number of MC replicates
B <- 30
## G-formula
gfmla.res <- fit.gfmla.mccs(
data = datstar,
a = a,
cov.e = cov.e,
B = B,
mc.seed = mc.seed,
return.var = TRUE,
args = gfmla.args)
cbind(est = round(gfmla.res$est, 2),
stde = round(sqrt(diag(gfmla.res$var)), 2),
bc.stde = round(sqrt(diag(gfmla.res$bc.var)), 2))
## IPW arguments
ipw.args <- list(formula = ipw.formula,
ps.formula = ps.formula,
inv.link = inv.link,
d.inv.link = d.inv.link)
## IPW estimation
ipw.res <- fit.ipw.mccs(
data = datstar,
cov.e = cov.e,
B = B,
mc.seed = mc.seed,
return.var = TRUE,
args = ipw.args)
load_all()
document()
load_all()
## IPW arguments
ipw.args <- list(formula = ipw.formula,
ps.formula = ps.formula,
inv.link = inv.link,
d.inv.link = d.inv.link)
## IPW estimation
ipw.res <- fit.ipw.mccs(
data = datstar,
cov.e = cov.e,
B = B,
mc.seed = mc.seed,
return.var = TRUE,
args = ipw.args)
cbind(est = round(ipw.res$est, 2),
stde = round(sqrt(diag(ipw.res$var)), 2),
bc.stde = round(sqrt(diag(ipw.res$bc.var)), 2))
## arguments for double robust estimation
dr.args <- list(formula = formula,
ps.formula = ps.formula,
inv.link = inv.link,
d.inv.link = d.inv.link)
## Double Robust
dr.res <- fit.dr.mccs(
data = datstar,
a = a,
cov.e = cov.e,
B = B,
mc.seed = mc.seed,
return.var = TRUE,
args = dr.args)
cbind(est = round(dr.res$est, 2),
stde = round(sqrt(diag(dr.res$var)), 2),
bc.stde = round(sqrt(diag(dr.res$bc.var)), 2))
knitr::opts_chunk$set(echo = TRUE)
## load the package
library(mismex)
library(devtools)
## load additional packages
library(MASS)
library(dplyr)
library(tidyverse)
library(ggplot2)
## define parameters
n = 2000                                  # sample size
seed = 1                                  # random number seed
mc.seed <- 123                            # MCCS seed
cov.e <- 0.36                             # var(epsilon)
inv.link <- inv.ident                     # inverse link
d.inv.link <- d.inv.ident                 # derivative of inverse link
g <- c(1.5, 0.7, 0.9, -0.6, -0.7, 0.4)    # outcome model parameters
formula <- "~A*L1 + A*L2"                 # outcome model formula
ps.formula <- "~L1 + L2"                  # propensity score model formula
ipw.formula <- "~A"                       # MSM formula
## generate data
set.seed(seed)
L1 <- rbinom(n, 1, 0.5)                                  # confounder 1
L2 <- rnorm(n, 1, sqrt(0.5))                             # confounder 2
A <- rnorm(n, 2 + 0.9*L1 - 0.6*L2, sqrt(1.1))            # exposure
a <- seq(min(A), max(A), length = 4)                     # grid of exposures
EY <- inv.link(model.matrix(as.formula(formula)) %*% g)  # mean of outcome
Y <- rnorm(n, EY, sqrt(0.16))                            # outcome
Astar <- A + rnorm(n, 0, sqrt(cov.e))                    # mismeasured A
datstar <- data.frame(Y, A = Astar, L1, L2)              # mismeasured data
head(datstar, 5)
## g-formula arguments
gfmla.args <- list(formula = formula,
inv.link = inv.link,
d.inv.link = d.inv.link)
## naive estimator
gfmla.naive <- fit.glm(data = datstar,
args = gfmla.args,
return.var = F)$est
## assess MCCS estimating function over grid of B values
gfmla.B.tuning <- tune.B(
get.psi = get.psi.glm,
data = datstar,
cov.e = cov.e,
BB = seq(1, 50, by = 2),
args = gfmla.args,
mc.seed = 123)
gfmla.B.tuning$plot
## number of MC replicates
B <- 30
## G-formula
gfmla.res <- fit.gfmla.mccs(
data = datstar,
a = a,
cov.e = cov.e,
B = B,
mc.seed = mc.seed,
return.var = TRUE,
args = gfmla.args)
cbind(est = round(gfmla.res$est, 2),
stde = round(sqrt(diag(gfmla.res$var)), 2),
bc.stde = round(sqrt(diag(gfmla.res$bc.var)), 2))
## IPW arguments
ipw.args <- list(formula = ipw.formula,
ps.formula = ps.formula,
inv.link = inv.link,
d.inv.link = d.inv.link)
## IPW estimation
ipw.res <- fit.ipw.mccs(
data = datstar,
cov.e = cov.e,
B = B,
mc.seed = mc.seed,
return.var = TRUE,
args = ipw.args)
cbind(est = round(ipw.res$est, 2),
stde = round(sqrt(diag(ipw.res$var)), 2),
bc.stde = round(sqrt(diag(ipw.res$bc.var)), 2))
rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(kableExtra)
library(devtools)
load_all()
# load simulation results from each of 10 clusters
setwd(dirname(getwd()))
sim.out.list <- lapply(
X = 0:9,
FUN = function(clust) {
cbind(clust,
read.csv(paste0("sim_data/sim4_dr_misspec/sd",
clust, ".csv")))
})
# true estimand
g <- 0.175
# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list) %>%
mutate(g.true = g,
ci.lower = est - qnorm(0.975) * se,
ci.upper = est + qnorm(0.975) * se,
ci.cov = g.true >= ci.lower & g.true <= ci.upper,
bcci.lower = est - qnorm(0.975) * bse,
bcci.upper = est + qnorm(0.975) * bse,
bcci.cov = g.true >= bcci.lower & g.true <= bcci.upper,
method = factor(method,
levels = c("gfmla", "ipw", "dr"),
labels = c("G-Formula", "IPW", "DR")),
type = factor(type,
levels = c("oracle", "naive", "rc", "mccs"),
labels = c("Oracle", "Naive", "Reg. Cal.", "MCCS")),
spec = factor(ifelse(ps == 0 & out == 0, "PS and OR",
ifelse(ps == 0 & out == 1, "PS",
ifelse(ps == 1 & out == 0, "OR", "Neither"))),
levels = c("PS and OR", "PS", "OR", "Neither")),
ps = factor(ps,
levels = c(0, 1),
labels = c("PS Correct", "PS Incorrect")),
out = factor(out,
levels = c(0, 1),
labels = c("Outcome Correct", "Outcome Incorrect")))
# number of sims per setting
n.rep <- nrow(sim.out) /
n_distinct(dplyr::select(sim.out, n, method, type, ps, out))
# summarize proportion of missing data by setting
sim.out %>%
group_by(n, method, type, ps, out) %>%
summarise(prop.error = mean(is.na(est))) %>%
filter(prop.error > 0) %>%
ungroup()
# colorblind friendly pallette
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')
# plot all estimators across 4 modeling scenarios
make.plot <- function(n. = 2000, vare. = 0.01) {
sim.out %>%
filter(n == n.,
vare == vare.) %>%
ggplot(aes(x = type,
y = est,
fill = type,
color = type)) +
geom_boxplot() +
geom_hline(yintercept = g,
linetype = "dashed",
color = "orange") +
facet_nested(method ~ ps + out, scales = "free") +
labs(y = "Parameter Estimate",
fill = "Type",
color = "Type") +
ggtitle(paste0("Empirical Distribution of Parameter Estimates"),
subtitle = paste0("n = ", n., "; ",
n.rep, " simulations per setting")) +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank()) +
scale_fill_manual(values = pal_light) +
scale_color_manual(values = pal_dark)
}
make.plot(n. = 2000)
