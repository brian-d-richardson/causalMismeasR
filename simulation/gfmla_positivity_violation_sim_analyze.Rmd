---
title: "MCCS G-Formula Positivity Violation Simulation Results"
author: "Brian Richardson"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output:
  html_document:
    code_folding: hide
---

```{r message = F, warning = F}

rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(kableExtra)
library(devtools)
load_all()

```

The goal of this program is to evaluate the Monte Carlo corrected score G-formula (MCCS G-FMLA) estimator in the presence of confounding and measurement error, with some positivity violation.

## Setup

Consider the following setup:

* two independent binary confounders $L_1 \sim \textrm{Bernoulli}(0.5), L_2 \sim \textrm{Bernoulli}(0.2)$,
* univariate continuous exposure $A$ with $A|L_1,L_2 \sim N(2+0.3L_1-0.5L_2, 0.35)$,
* mismeasured exposure $A^* = A + \epsilon$, where $\epsilon \sim N(0, 0.25)$,
* binary outcome $Y$ with $\textrm{E}(Y|A,L) = \textrm{logit}^{-1}(-2+0.7A-0.6L_1+0.4L_2-0.4AL_1-0.2AL_2)$.

This data generating process leads to a mean potential outcome at $a$ of $\textrm{E}\{Y(a)\} = 0.4\textrm{logit}^{-1}(-2+0.7a) + 0.4\textrm{logit}^{-1}(-2.6+0.3a) + 0.1\textrm{logit}^{-1}(-1.6+0.5a) + 0.1\textrm{logit}^{-1}(-2.2+0.1a)$.

The estimand of interest in these simulations is the dose response curve $\{\textrm{E}[Y(a)] : a \in \mathcal{A}\}$.

## Methods

In these simulations, we compare six methods:

1) Oracle GLM
2) Oracle G-Formula
3) Naive GLM
4) Naive G-Formula
5) Corrected GLM
6) Corrected G-Formula

The GLM methods fit a logistic regression mode of $Y$ on $A$ and $L$ with all interaction terms between $A$ and $L$, then estimate $\textrm{E}\{Y(a)\}$ with $\textrm{logit}^{-1}(\widehat\beta_0+\widehat\beta_aa)$. The G-formula methods fit the same logistic regression models, then estimate $\textrm{E}\{Y(a)\}$ with $n^{-1}\sum_{i=1}^n\textrm{logit}^{-1}(\widehat\beta_0+\widehat\beta_Aa+\widehat\beta_{L_1}L_{1i}+\widehat\beta_{L_2}L_{2i}+\widehat\beta_{A:L_1}aL_{1i}+\widehat\beta_{A:L_2}aL_{2i})$.

The oracle methods use the true exposure values $A$, which are not observed in practice. The naive methods treat $A^*$ as $A$, assuming there is no measurement error. The corrected methods use the Monte-Carlo corrected score versions of the estimating functions, which account for measurement error.

## Results

We first check for simulations with errors.

```{r}

# load simulation results from each of 10 clusters
sim.out.list <- lapply(
  X = 0:9,
  FUN = function(clust) {
    cbind(clust,
          read.csv(paste0("sim_data/gfmla_positivity_violation_data/v2/sd",
                          clust, ".csv")))
  })


# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)

# true estimands
g <- c(-2, 0.7, -0.6, 0.4, -0.4, -0.2)          # outcome model parameters
a <- 0:4                                        # exposure value of interest
EYa.true <- 0.4 * inv.logit(-2 + 0.7 * a) +     # true dose response curve at a
  0.4 * inv.logit(-2.6 + 0.3 * a) +
  0.1 * inv.logit(-1.6 + 0.5 * a) +
  0.1 * inv.logit(-2.2 + 0.1 * a)

# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare))

# make long data frame
sim.out.long <- sim.out %>% 
  pivot_longer(cols = starts_with("est") | 
                      starts_with("ste") |
                      starts_with("bcs"), 
               names_to = "method.aa",
               values_to = "val") %>% 
    mutate(method = factor(substr(method.aa, 5, 6),
                           levels = c("OG", "NG", "CG"),
                           labels = c("Oracle G-Formula",
                                      "Naive G-Formula",
                                      "Corrected G-Formula")),
           aa = factor(substr(method.aa, 8, 8)),
           a = factor(a[aa]),
           name = factor(substr(method.aa, 1, 3)),
           EYa.true = EYa.true[aa]) %>% 
  dplyr::select(-method.aa) %>% 
  group_by(clust, n, B, vare, method, aa, a, name) %>% 
  mutate(id = row_number()) %>% 
  pivot_wider(names_from = name,
              values_from = val,
              id_cols = c(clust, n, B, vare, method, aa, a, EYa.true, id)) %>% 
  mutate(ci.lower = est - qnorm(0.975) * ste,
         ci.upper = est + qnorm(0.975) * ste,
         ci.cov = EYa.true >= ci.lower & EYa.true <= ci.upper,
         bcci.lower = est - qnorm(0.975) * bcs,
         bcci.upper = est + qnorm(0.975) * bcs,
         bcci.cov = EYa.true >= bcci.lower & EYa.true <= bcci.upper)

```

We first check for simulations with errors.

```{r}

# summarize proportion of missing data by setting
ftc.dat <- sim.out.long %>% 
  filter(aa == 1) %>% 
  group_by(method, n, B, vare) %>% 
  summarise(prop.error = mean(is.na(est)))

ftc.dat %>% 
  filter(prop.error > 0) %>% 
  ungroup()

```

```{r}

# extract simulation parameters
n <- unique(sim.out$n)

# make labels for plots
method.labs <- c("Oracle G-Formula",
                 "Naive G-Formula",
                 "G-Formula CS")

names(method.labs) <- c("OL", "OG",
                        "NL", "NG",
                        "CL", "CG")

n.labs <- paste0("n = ", n)
names(n.labs) <- n

a.labs <- paste0("a = ", a)
names(a.labs) <- a

# colorblind friendly pallette
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')

```

```{r}

# separate plots for each exposure value a, and for selected methods
plot.by.a <- function(a., title = T) {
  
  plot <- sim.out.long %>% 
    filter(a == a.) %>% 
  ggplot(aes(x = method,
             y = est,
             fill = method,
             color = method)) +
    geom_boxplot() +
    geom_hline(aes(yintercept = EYa.true),
               linetype = "dashed",
               color = "orange") +
    facet_wrap(~ n,
               scales = "free", 
               ncol = 1,
               labeller = labeller(n = n.labs)) +
    labs(y = "Parameter Estimate",
         fill = "Method",
         color = "Method") +
    theme_bw() +
    theme(axis.title.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.text.x = element_blank(),
          legend.position = "bottom") +
    scale_fill_manual(values = pal_light,
                      labels = method.labs) +
    scale_color_manual(values = pal_dark,
                      labels = method.labs)
  
  if (title) {
    plot <- plot +
      ggtitle(paste0("Empirical Distribution of Parameter Estimates"),
              subtitle = paste0("a = ", a., "; ",
                                n.rep, " simulations per setting"))

  }
  return(plot)
}

```

### Plots of Simulation Results

Below are boxplots of the empirical distributions of estimators for $\textrm{E}\{Y(a)\}$ at exposure values $a = 0,1,2,3,4$.

```{r message = F, eval = T}

plot.by.a(a. = 0)
plot.by.a(a. = 1)
plot.by.a(a. = 2)
plot.by.a(a. = 3)
plot.by.a(a. = 4)

```

### Tables of Simulation Results

Below is a table for the primary estimand of interest ($a=3$) and for $n \in \{800, 8000\}$. It includes empirical bias, empirical standard error (ESE), average estimated standard error (ASE), and empirical coverage probability of the 95% CI.

```{r}

tbl <- sim.out.long %>% 
  filter(a == 3 &
         n %in% c(400, 800, 8000)) %>% 
  group_by(n, method, a) %>% 
  summarise(bias = 100 * mean(est - EYa.true, na.rm = T),
            emp.se = 100 * sd(est, na.rm = T),
            est.se = 100 * mean(ste, na.rm = T),
            ci.cov = 100 * mean(ci.cov, na.rm = T),
            bcest.se = 100 * mean(bcs, na.rm = T),
            bcci.cov = 100 * mean(bcci.cov, na.rm = T)) %>% 
  left_join(ftc.dat) %>% 
  mutate(ftc = 100 * prop.error) %>% 
  dplyr::select(n, method, bias, emp.se,
                est.se, ci.cov, bcest.se, bcci.cov, ftc)

kbl <- tbl %>% 
  kable(format = "latex",
        digits = c(0, 0, 2, 2, 2, 1, 2, 1, 1),
        align = c(rep("c", 2),
                  rep("r", 7)),
        booktabs = TRUE,
        linesep = c("", "", "\\addlinespace"),
        escape = FALSE,
        col.names = c("n", "Method",
                      "Bias", "ESE",
                      "ASE", "Cov",
                      "ASE", "Cov",
                      "%FTC")) %>%
  add_header_above(c(" " = 4,
                     "Crude" = 2,
                     "BC" = 2,
                     " " = 1)) %>% 
  kable_styling("striped") %>% 
  row_spec(row = 0, bold = TRUE)

tbl

```
