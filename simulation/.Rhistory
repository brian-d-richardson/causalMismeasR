axis.ticks.x = element_blank(),
axis.text.x = element_blank()) +
scale_fill_manual(values = pal_light,
labels = method.labs) +
scale_color_manual(values = pal_dark,
labels = method.labs)
}
plot.by.a(a. = 0, est_cutoff = 4)
plot.by.a(a. = 1, est_cutoff = 3)
plot.by.a(a. = 2, est_cutoff = 2)
plot.by.a(a. = 3, est_cutoff = 2)
plot.by.a(a. = 4, est_cutoff = 2)
plot.by.a(a. = 3, method. = c("OG", "NG", "CG"), n. = 800, vare. = 0.25)
tbl.a3 <- sim.out.long %>%
filter(a == 3,
n == 800,
vare == 0.25) %>%
group_by(method) %>%
summarise(bias = mean(est - EYa.true, na.rm = T),
emp.se = sd(est, na.rm = T),
est.se = mean(ste, na.rm = T),
mse = mean(est - EYa.true))
tbl.a3 %>%
kable(digits = 3,
col.names = c("Method", "Bias", "ESE", "ASE", "MSE"),
caption = "Estimated E{Y(a)} for a = 3, n = 800, vare = 0.25") %>%
kable_styling("striped")
rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(kableExtra)
# load simulation results from each of 10 clusters
sim.out.list <- lapply(
X = 0:9,
FUN = function(clust) {
cbind(clust,
read.csv(paste0("sim_data/ipw_data/sd",
clust, ".csv")))
})
# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)
# true MSM parameters
g <- c(0.45, 0.20, 0.15, 0.15)
# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare))
# make long data frame
sim.out.long <- sim.out %>%
pivot_longer(cols = starts_with("ghat") | starts_with("stde"),
names_to = "method.param",
values_to = "val") %>%
mutate(method = factor(substr(method.param, 6, 7),
levels = c("OL", "OI",
"NL", "NI",
"CL", "CI")),
param = factor(substr(method.param, 9, 9)),
name = factor(substr(method.param, 1, 4)),
g.true = g[param]) %>%
dplyr::select(-method.param) %>%
group_by(clust, n, B, vare, method, param, name) %>%
mutate(id = row_number()) %>%
pivot_wider(names_from = name,
values_from = val,
id_cols = c(clust, n, B, vare, method,
param, g.true, id))
# summarize proportion of missing data by setting
sim.out.long %>%
filter(param == 1) %>%
group_by(method, n, B, vare) %>%
summarise(prop.error = mean(is.na(ghat))) %>%
filter(prop.error > 0) %>%
ungroup()
# extract simulation parameters
n <- unique(sim.out$n)
B <- unique(sim.out$B)
vare <- unique(sim.out$vare)
# make labels for plots
method.labs <- c("Oracle Linear",
"Naive Linear",
"Corrected Linear",
"Oracle IPW",
"Naive IPW",
"Corrected IPW")
names(method.labs) <- c("OL", "NL", "CL",
"OI", "NI", "CI")
n.labs <- paste0("n = ", n)
names(n.labs) <- n
B.labs <- paste0("B = ", B)
names(B.labs) <- B
vare.labs <- paste0("sigma_e = ", vare)
names(vare.labs) <- vare
param.labs <- paste0("\u03b3", c("0", "1", "2", "3"))
names(param.labs) <- 1:4
# colorblind friendly pallette
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')
# separate plots for each sample size
plot.by.var <- function(vare. = 0.05, est_cutoff = Inf) {
ggplot(
data = filter(sim.out.long,
vare == vare.,
abs(ghat - g.true) < est_cutoff),
aes(x = method,
y = ghat,
fill = method,
color = method)) +
geom_boxplot() +
stat_summary(fun = mean,
geom = "point",
shape = 8,
size = 2,
orientation = "x",
show.legend = F) +
geom_hline(aes(yintercept = g.true),
linetype = "dashed",
color = "orange") +
facet_grid(n ~ param,
scales = "free",
labeller = labeller(n = n.labs,
param = param.labs)) +
labs(y = "Parameter Estimate",
fill = "Method",
color = "Method") +
ggtitle(paste0("Empirical Distribution of Parameter Estimates"),
subtitle = paste0(n.rep, " simulations per setting")) +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank()) +
scale_fill_manual(values = pal_light,
labels = method.labs) +
scale_color_manual(values = pal_dark,
labels = method.labs)
}
plot.by.var()
tbl <- sim.out.long %>%
group_by(param, method, n, B, vare) %>%
summarise(bias = mean(ghat - g.true, na.rm = T),
emp.se = sd(ghat, na.rm = T),
est.se = mean(stde)) %>%
gather(key, value, bias:est.se) %>%
unite(Group, param, key) %>%
spread(Group, value)
setNames(tbl, sub(".+_", "", names(tbl))) %>%
kable(digits = 3) %>%
kable_styling("striped") %>%
add_header_above(c(" " = 4,
"Component 1" = 3,
"Component 2" = 3,
"Component 3" = 3,
"Component 4" = 3))
rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(kableExtra)
# load simulation results from each of 10 clusters
sim.out.list <- lapply(
X = 0:9,
FUN = function(clust) {
cbind(clust,
read.csv(paste0("sim_data/ipw_data/version3/sd",
clust, ".csv")))
})
# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)
# true MSM parameters
g <- c(0.45, 0.20, 0.15, 0.15)
# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare))
# make long data frame
sim.out.long <- sim.out %>%
pivot_longer(cols = starts_with("ghat") | starts_with("stde"),
names_to = "method.param",
values_to = "val") %>%
mutate(method = factor(substr(method.param, 6, 7),
levels = c("OL", "OI",
"NL", "NI",
"CL", "CI")),
param = factor(substr(method.param, 9, 9)),
name = factor(substr(method.param, 1, 4)),
g.true = g[param]) %>%
dplyr::select(-method.param) %>%
group_by(clust, n, B, vare, method, param, name) %>%
mutate(id = row_number()) %>%
pivot_wider(names_from = name,
values_from = val,
id_cols = c(clust, n, B, vare, method,
param, g.true, id))
# summarize proportion of missing data by setting
sim.out.long %>%
filter(param == 1) %>%
group_by(method, n, B, vare) %>%
summarise(prop.error = mean(is.na(ghat))) %>%
filter(prop.error > 0) %>%
ungroup()
# extract simulation parameters
n <- unique(sim.out$n)
B <- unique(sim.out$B)
vare <- unique(sim.out$vare)
# make labels for plots
method.labs <- c("Oracle Linear",
"Naive Linear",
"Corrected Linear",
"Oracle IPW",
"Naive IPW",
"Corrected IPW")
names(method.labs) <- c("OL", "NL", "CL",
"OI", "NI", "CI")
n.labs <- paste0("n = ", n)
names(n.labs) <- n
B.labs <- paste0("B = ", B)
names(B.labs) <- B
vare.labs <- paste0("sigma_e = ", vare)
names(vare.labs) <- vare
param.labs <- paste0("\u03b3", c("0", "1", "2", "3"))
names(param.labs) <- 1:4
# colorblind friendly pallette
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')
# separate plots for each sample size
plot.by.var <- function(vare. = 0.05, est_cutoff = Inf) {
ggplot(
data = filter(sim.out.long,
vare == vare.,
abs(ghat - g.true) < est_cutoff),
aes(x = method,
y = ghat,
fill = method,
color = method)) +
geom_boxplot() +
stat_summary(fun = mean,
geom = "point",
shape = 8,
size = 2,
orientation = "x",
show.legend = F) +
geom_hline(aes(yintercept = g.true),
linetype = "dashed",
color = "orange") +
facet_grid(n ~ param,
scales = "free",
labeller = labeller(n = n.labs,
param = param.labs)) +
labs(y = "Parameter Estimate",
fill = "Method",
color = "Method") +
ggtitle(paste0("Empirical Distribution of Parameter Estimates"),
subtitle = paste0(n.rep, " simulations per setting")) +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank()) +
scale_fill_manual(values = pal_light,
labels = method.labs) +
scale_color_manual(values = pal_dark,
labels = method.labs)
}
plot.by.var()
tbl <- sim.out.long %>%
group_by(param, method, n, B, vare) %>%
summarise(bias = mean(ghat - g.true, na.rm = T),
emp.se = sd(ghat, na.rm = T),
est.se = mean(stde)) %>%
gather(key, value, bias:est.se) %>%
unite(Group, param, key) %>%
spread(Group, value)
setNames(tbl, sub(".+_", "", names(tbl))) %>%
kable(digits = 3) %>%
kable_styling("striped") %>%
add_header_above(c(" " = 4,
"Component 1" = 3,
"Component 2" = 3,
"Component 3" = 3,
"Component 4" = 3))
rm(list = ls())
library(rootSolve)
library(MASS)
library(mvtnorm)
library(tidyr)
library(devtools)
#setwd(dirname(getwd()))
load_all()
rm(list = ls())
library(devtools)
library(statmod)
library(pbapply)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(MASS)
#setwd(dirname(getwd()))
load_all()
# define parameters -------------------------------------------------------
seed <- 1                                      # random seed
n <- 800                                       # sample size
B <- 80                                        # MC replicates
mc.seed <- 123                                 # MC seed
gg <- c(0.4, 0.15, 0.15, 0.2,
0.1, 0.1, 0, -0.1)                     # Y|A,L parameters
g <- gg[1:4] + 0.5*gg[5:8]                     # MSM parameters
glm.formula <- "~A1*L + A2*L + A3*L"           # Y|A,L model formula
ipw.formula <- "~A1 + A2 + A3"                 # MSM formula
ps.formula <- "~L"                             # PS model formula
inv.link <- inv.ident;                         # MSM link function
d.inv.link <- d.inv.ident;                     # MSM derivative of link
vare <- 0.05                                   # variance of A1, A2
cov.e <- diag(c(vare, vare, 0))                # measurement error variance
coef.a.l <- matrix(
data = c(0, 0.4, 0, -0.4, 0.2, -0.1),        # coefs in A|L model
nrow = 3, byrow = T)
var.a.l <- c(0.09, 0.09, 0.09)                 # variance of A|L
# generate data -----------------------------------------------------------
set.seed(seed)                                 # seed for reproducibility
L <- runif(n)                                  # confounder
A <- mvrnorm(n = n,                            # true exposure
mu = c(0, 0, 0),
Sigma = diag(var.a.l)) +
cbind(1, L) %*% t(coef.a.l)
colnames(A) = paste0("A", 1:3)
Astar <- A + mvrnorm(n = n,                    # mismeasured exposure
m = c(0, 0, 0),
Sigma = cov.e)
Y_prob <- cbind(1, A, L, A*L) %*% gg           # mean of binary outcome
Y_prob[Y_prob < 0] <- 0                        # correct Y_prob in rare cases
Y_prob[Y_prob > 1] <- 1
Y <- rbinom(n, 1, Y_prob)                      # binary outcome
colnames(A) <- colnames(Astar) <- c("A1", "A2", "A3")
dat0 <- data.frame(Y, A, L)                    # oracle data
datstar <- data.frame(Y, Astar, L)             # mismeasured data
# store values for estimation ---------------------------------------------
len.A <- ncol(A)                               # dimension of A
mean.a <- colMeans(A)                          # marginal mean of A
cov.a <- cov(A)                                # marginal covariance of A
args.glm <- list(formula = glm.formula,        # arguments for fitting GLM
inv.link = inv.link,
d.inv.link = d.inv.link)
args.ipw <- list(formula = ipw.formula,        # arguments for fitting IPW
ps.formula = ps.formula,
inv.link = inv.link,
d.inv.link = d.inv.link)
data = datstar
args = args.ipw
# (i) naive logistic regression
res.NL <- fit.glm(data = datstar,
args = args.glm)
# (iv) naive IPW estimator
res.NI <- fit.ipw(data = datstar,
args = args.ipw,
mean.a = mean.a,
cov.a = cov.a,
start = res.NL$est[1:4])
start = res.NI$est[1:4]
mean.a
colMeans(Astar)
cov.a
cov(Astar) - cov.e
start = NULL
return.var = TRUE
coef.a.l = NULL
var.a.l = NULL
## store dimensions
n <- nrow(data)                                            # sample size
ind.A <- grepl("A", colnames(data))                        # exposure columns
A <- as.matrix(data[,ind.A])
L <- as.matrix(data[,grepl("L", colnames(data))])
len.A <- sum(ind.A)                                        # dim of exposure
len.msm <- ncol(model.matrix(                              # dim of msm params
terms(as.formula(formula)), data = data))
len.ps <- ncol(model.matrix(terms(as.formula(ps.formula)), # PS model params
data = data))                  # dim of ps params
## store dimensions
n <- nrow(data)                                            # sample size
ind.A <- grepl("A", colnames(data))                        # exposure columns
A <- as.matrix(data[,ind.A])
L <- as.matrix(data[,grepl("L", colnames(data))])
len.A <- sum(ind.A)                                        # dim of exposure
len.msm <- ncol(model.matrix(                              # dim of msm params
terms(as.formula(formula)), data = data))
formula = ps.formula
len.msm <- ncol(model.matrix(                              # dim of msm params
terms(as.formula(formula)), data = data))
len.ps <- ncol(model.matrix(terms(as.formula(ps.formula)), # PS model params
data = data))                  # dim of ps params
d.cov.e <- diag(as.matrix(cov.e))                          # cov.e vector
formula = ipw.formula
len.msm <- ncol(model.matrix(                              # dim of msm params
terms(as.formula(formula)), data = data))
len.ps <- ncol(model.matrix(terms(as.formula(ps.formula)), # PS model params
data = data))                  # dim of ps params
d.cov.e <- diag(as.matrix(cov.e))                          # cov.e vector
# set starting value if not supplied
if (is.null(start)) { start <- rep(0, len.msm) }
# compute marginal mean and covariance of A if not supplied
if (is.null(mean.a)) { mean.a <- colMeans(as.matrix(A)) }
if (is.null(cov.a)) {
if (is.vector(A)) {
cov.a <- var(A) - cov.e
} else {
cov.a <- cov(A) - cov.e
}
}
# fit propensity score model if not supplied
if (is.null(coef.a.l)) {
model.a.l <- lm(as.formula(paste0("A", ps.formula)))
coef.a.l <- t(coef(model.a.l))
var.a.l <- apply(as.matrix(model.a.l$residuals, ncol = len.a), 2, var) -
d.cov.e
}
var.a.l
coef.a.l
## get naive estimates to use as starting values
root.naive <- fit.ipw(data = data, args = args,
start = start, return.var = F)$est[1:len.msm]
root.naive
start
## create MCCS IPW estimating function
get.psi.ipw.mccs <- make.mccs(
get.psi = function(data, g, args, return.sums = T) {
get.psi.ipw(data = data, args = args,
g = g,
mean.a = mean.a, cov.a = cov.a,
return.sums = return.sums) },
data = data, args = args,
cov.e = cov.e, B = B, mc.seed = mc.seed)
get.psi.ipw.mccs
# Solve MCCS IPW equation
root <- tryCatch(
expr = rootSolve::multiroot(
f = function(xx) get.psi.ipw.mccs(x = c(xx, c(coef.a.l), log(var.a.l))),
start = root.naive)$root,
warning = function(w) {message(w); rep(NA, len.msm)},
error = function(e) {message(e); rep(NA, len.msm)})
root
# combine MSM and PS model parameters
est <- c(root, coef.a.l, log(var.a.l))
names(est) <- c(
paste0("g.", 0:(len.msm - 1)),
paste0("coef.a.l.", 1:(len.A*len.ps)),
paste0("log.var.a.l", 1:len.A))
est
x = est
get.psi.ipw.mccs(x = x, return.sums = F)
matrix(x[len.msm + 1:(len.A*len.ps)],
ncol = len.ps, byrow = F)
coef.a.l
exp(tail(x, len.A))
d.cov.e
evar <- matrix(NA, len.msm + len.ps, len.msm + len.ps)
if (return.var) {
evar <- tryCatch(
expr = get.sand.est(
ghat = est,
n = n,
get.psi = function(x) {
cbind(
get.psi.ipw.mccs(x = x, return.sums = F),
get.psi.ps(
data = data, ps.formula = ps.formula,
coef.a.l = matrix(x[len.msm + 1:(len.A*len.ps)],
ncol = len.ps, byrow = F),
var.a.l = exp(tail(x, len.A)) + d.cov.e,
return.sums = F)) }),
warning = function(w) {message(w); evar},
error = function(e) {message(e); evar})
}
evar1 <- evar
evar1
evar <- matrix(NA, len.msm + len.ps, len.msm + len.ps)
if (return.var) {
evar <- tryCatch(
expr = get.sand.est(
ghat = est,
n = n,
get.psi = function(x) {
cbind(
get.psi.ipw.mccs(x = x, return.sums = F),
get.psi.ps(
data = data, ps.formula = ps.formula,
coef.a.l = matrix(x[len.msm + 1:(len.A*len.ps)],
ncol = len.ps, byrow = F),
var.a.l = exp(tail(x, len.A)) + d.cov.e,
return.sums = F)) }),
warning = function(w) {message(w); evar},
error = function(e) {message(e); evar})
}
evar2 <- evar
sqrt(diag(evar1)[1:4])
sqrt(diag(evar2)[1:4])
evar <- matrix(NA, len.msm + len.ps, len.msm + len.ps)
if (return.var) {
evar <- tryCatch(
expr = get.sand.est(
ghat = est,
n = n,
get.psi = function(x) {
cbind(
get.psi.ipw.mccs(x = x, return.sums = F),
get.psi.ps(
data = data, ps.formula = ps.formula,
coef.a.l = matrix(x[len.msm + 1:(len.A*len.ps)],
ncol = len.ps, byrow = F),
var.a.l = exp(tail(x, len.A)),# + d.cov.e,
return.sums = F)) }),
warning = function(w) {message(w); evar},
error = function(e) {message(e); evar})
}
evar2 <- evar
sqrt(diag(evar1)[1:4])
sqrt(diag(evar2)[1:4])
