E.A.AstarL <- E.A + c(
c(Sigma.AA, Sigma.LA) %*%
solve(rbind(cbind(Sigma.AA + cov.e, Sigma.LA),
cbind(t(Sigma.LA), Sigma.LL))) %*%
t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F)))))
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F))
datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F))
t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F))))
aaa <- t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F))))
solve(rbind(cbind(Sigma.AA + cov.e, Sigma.LA),
cbind(t(Sigma.LA), Sigma.LL))) %*%
t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F))))
aaa <- solve(rbind(cbind(Sigma.AA + cov.e, Sigma.LA),
cbind(t(Sigma.LA), Sigma.LL))) %*%
t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F))))
c(Sigma.AA, Sigma.LA)
Sigma.AA
Sigma.LA
# estimate E(A | Astar, L)
E.A.AstarL <- E.A + c(
cbind(Sigma.AA, Sigma.LA) %*%
solve(rbind(cbind(Sigma.AA + cov.e, Sigma.LA),
cbind(t(Sigma.LA), Sigma.LL))) %*%
t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F)))))
E.A.AstarL
aaa <-
cbind(Sigma.AA, Sigma.LA) %*%
solve(rbind(cbind(Sigma.AA + cov.e, Sigma.LA),
cbind(t(Sigma.LA), Sigma.LL))) %*%
t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F))))
View(aaa)
# estimate E(A | Astar, L)
E.A.AstarL <- E.A + t(
cbind(Sigma.AA, Sigma.LA) %*%
solve(rbind(cbind(Sigma.AA + cov.e, Sigma.LA),
cbind(t(Sigma.LA), Sigma.LL))) %*%
t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F)))))
View(E.A.AstarL)
# create data set for regression calibration
datrc <- data.frame(Y, A = E.A.AstarL, L)
View(datrc)
# create data set for regression calibration
datrc <- data.frame(Y,
A1 = E.A.AstarL[,1],
A2 = E.A.AstarL[,3],
A2 = E.A.AstarL[,3],
L)
# compare estimated E(A | Astar, L) to true A
ggplot(NULL,
aes(x = E.A.AstarL[,1],
y = A[,1])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
ggplot(NULL,
aes(x = E.A.AstarL[,2],
y = A[,2])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
ggplot(NULL,
aes(x = E.A.AstarL[,3],
y = A[,3])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
n = 800; vare = 0.0001; B = 2; seed = 1;
gg <- c(0.4, 0.15, 0.15, 0.2,
0.1, 0.1, 0, -0.1)                     # Y|A,L parameters
glm.formula <- "~A1*L + A2*L + A3*L"           # Y|A,L model formula
ipw.formula <- "~A1 + A2 + A3"                 # MSM formula
ps.formula <- "~L"                             # PS model formula
inv.link <- inv.ident;                         # MSM link function
d.inv.link <- d.inv.ident;                     # MSM derivative of link
cov.e <- diag(c(vare, vare, 0))                # measurement error variance
mc.seed <- 123                                 # MCCS seed value
coef.a.l <- matrix(
data = c(0, 0.4, 0, -0.4, 0.2, -0.1),        # coefs in A|L model
nrow = 3, byrow = T)
var.a.l <- c(0.09, 0.09, 0.09)                 # variance of A|L
set.seed(seed)                                 # seed for reproducibility
L <- runif(n)                                  # confounder
A <- mvrnorm(n = n,                            # true exposure
mu = c(0, 0, 0),
Sigma = diag(var.a.l)) +
cbind(1, L) %*% t(coef.a.l)
colnames(A) = paste0("A", 1:3)
Astar <- A + mvrnorm(n = n,                    # mismeasured exposure
m = c(0, 0, 0),
Sigma = cov.e)
Y_prob <- cbind(1, A, L, A*L) %*% gg           # mean of binary outcome
Y_prob[Y_prob < 0] <- 0                        # correct Y_prob in rare cases
Y_prob[Y_prob > 1] <- 1
Y <- rbinom(n, 1, Y_prob)                      # binary outcome
colnames(A) <- colnames(Astar) <- c("A1", "A2", "A3")
dat0 <- data.frame(Y, A, L)                    # oracle data
datstar <- data.frame(Y, Astar, L)             # mismeasured data
len.A <- ncol(A)                               # dimension of A
mean.a <- colMeans(A)                          # marginal mean of A
cov.a <- cov(A)                                # marginal covariance of A
args.glm <- list(formula = glm.formula,        # arguments for fitting GLM
inv.link = inv.link,
d.inv.link = d.inv.link)
args.ipw <- list(formula = ipw.formula,        # arguments for fitting IPW
ps.formula = ps.formula,
inv.link = inv.link,
d.inv.link = d.inv.link)
# estimate means and covariances
E.A <- colMeans(datstar[,c("A1","A2","A3")])            # E(A)                          # E(A)
E.L <- mean(datstar$L)                                  # E(L)
Sigma.AA <- cov(datstar[,c("A1","A2","A3")]) - cov.e    # Cov(A)
Sigma.LA <- cov(datstar[,c("A1","A2","A3")], datstar$L) # Cov(A, L)
Sigma.LL <- var(datstar$L)                              # Cov(L)
# estimate E(A | Astar, L)
E.A.AstarL <- E.A + t(
cbind(Sigma.AA, Sigma.LA) %*%
solve(rbind(cbind(Sigma.AA + cov.e, Sigma.LA),
cbind(t(Sigma.LA), Sigma.LL))) %*%
t(as.matrix(datstar[,c("A1", "A2", "A3", "L")] -
do.call(rbind, replicate(n, c(E.A, E.L), simplify = F)))))
# create data set for regression calibration
datrc <- data.frame(Y,
A1 = E.A.AstarL[,1],
A2 = E.A.AstarL[,3],
A2 = E.A.AstarL[,3],
L)
# compare estimated E(A | Astar, L) to true A
ggplot(NULL,
aes(x = E.A.AstarL[,1],
y = A[,1])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
ggplot(NULL,
aes(x = E.A.AstarL[,2],
y = A[,2])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
ggplot(NULL,
aes(x = E.A.AstarL[,3],
y = A[,3])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
# (i) naive IPW estimator
res.NI <- fit.ipw(data = datstar,
args = args.ipw)
# (ii) oracle IPW estimator
res.OI <- fit.ipw(data = dat0,
args = args.ipw,
start = res.NI$est[1:4])
# (iii) regression calibration IPW estimator
res.RI <- fit.ipw(data = datrc,
args = args.ipw,
start = res.NI$est[1:4])
# create data set for regression calibration
datrc <- data.frame(Y,
A1 = E.A.AstarL[,1],
A2 = E.A.AstarL[,3],
A3 = E.A.AstarL[,3],
L)
# compare estimated E(A | Astar, L) to true A
ggplot(NULL,
aes(x = E.A.AstarL[,1],
y = A[,1])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
# compare estimated E(A | Astar, L) to true A
ggplot(NULL,
aes(x = E.A.AstarL[,2],
y = A[,2])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
# compare estimated E(A | Astar, L) to true A
ggplot(NULL,
aes(x = E.A.AstarL[,3],
y = A[,3])) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
# create data set for regression calibration
datrc <- data.frame(Y,
A1 = E.A.AstarL[,1],
A2 = E.A.AstarL[,3],
A3 = E.A.AstarL[,3],
L)
# (i) naive IPW estimator
res.NI <- fit.ipw(data = datstar,
args = args.ipw)
# (ii) oracle IPW estimator
res.OI <- fit.ipw(data = dat0,
args = args.ipw,
start = res.NI$est[1:4])
# (iii) regression calibration IPW estimator
res.RI <- fit.ipw(data = datrc,
args = args.ipw,
start = res.NI$est[1:4])
# compare estimated E(A | Astar, L) to true A
ggplot(NULL,
aes(x = E.A.AstarL,
y = A)) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
View(datrc)
View(dat0)
View(datrc)
# create data set for regression calibration
datrc <- data.frame(Y,
A1 = E.A.AstarL[,1],
A2 = E.A.AstarL[,2],
A3 = E.A.AstarL[,3],
L)
# compare estimated E(A | Astar, L) to true A
ggplot(NULL,
aes(x = E.A.AstarL,
y = A)) +
geom_point() +
geom_abline(slope = 1,
color = "blue")
# (i) naive IPW estimator
res.NI <- fit.ipw(data = datstar,
args = args.ipw)
# (ii) oracle IPW estimator
res.OI <- fit.ipw(data = dat0,
args = args.ipw,
start = res.NI$est[1:4])
# (iii) regression calibration IPW estimator
res.RI <- fit.ipw(data = datrc,
args = args.ipw,
start = res.NI$est[1:4])
# (iii) MCCS IPW estimator
res.CI <- fit.ipw.mccs(data = datstar,
args = args.ipw,
cov.e = cov.e, B = B, mc.seed = mc.seed,
mean.a = colMeans(Astar),
cov.a = cov(Astar) - cov.e,
start = res.NI$est[1:4])
# combine results: estimates and std errors for 4 parameters
ret <- c(
n, vare, B, seed,
res.OI$est[1:4], res.NI$est[1:4],
res.RI$est[1:4], res.CI$est[1:4],
sqrt(c(
diag(res.OI$var)[1:4], diag(res.NI$var)[1:4],
diag(res.RI$var)[1:4], diag(res.CI$var)[1:4],
diag(res.OI$bc.var)[1:4], diag(res.NI$bc.var)[1:4],
diag(res.RI$bc.var)[1:4], diag(res.CI$bc.var)[1:4]
)))
# return result (numeric vector of length 40)
names(ret) <- c(
"n", "vare", "B", "seed",
apply(tidyr::expand_grid(
c("ghat", "stde", "bste"),
c("OI", "NI", "RI", "CI"),
1:4), 1, paste, collapse="."))
ret
res.OI$est[1:4]
res.RI$est[1:4]
res.CI$est[1:4]
res.NI$est[1:4]
rm(list = ls())
library(rootSolve)
library(MASS)
library(mvtnorm)
library(tidyr)
library(devtools)
setwd(dirname(getwd()))
load_all()
getwd()
args = 1
base.seed <- 10^6 * as.integer(args)
# number of sims per cluster
n.sim <- 100
n.sim = 1
# varied parameters
n <- 800                          # sample size
B <- 80                           # number of MC replicates
vare <- 0.05                      # measurement error variance for A1, A2
# create simulation input
sim.in <- expand.grid(n = n,
B = B,
vare = vare,
sim.id = 1:n.sim + base.seed)
# run simulations
sim.out <- pbapply::pbvapply(
X = 1:nrow(sim.in),
FUN = function(ii) {
sim.ipw(n = sim.in$n[ii],
B = sim.in$B[ii],
vare = sim.in$vare[ii],
seed = sim.in$sim.id[ii])
},
FUN.VALUE = numeric(52)) |>
t()
rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(kableExtra)
library(devtools)
load_all()
# load simulation results from each of 10 clusters
sim.out.list <- lapply(
X = 0:9,
FUN = function(clust) {
cbind(clust,
read.csv(paste0("sim_data/gfmla_nonlinear_data/sd",
clust, ".csv")))
})
# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)
# true estimands
g <- c(0, 0.25, 0.5, -0.5, 1)          # outcome model parameters
a <- -1:2                                        # exposure value of interest
EYa.true <- g[1] + 0.5*g[5] + a*g[2] + a^2*g[3] + a^3*g[4]
# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare))
# make long data frame
sim.out.long <- sim.out %>%
pivot_longer(cols = starts_with("est") |
starts_with("ste") |
starts_with("bcs"),
names_to = "method.aa",
values_to = "val") %>%
mutate(method = factor(substr(method.aa, 5, 6),
levels = c("OG", "NG", "CG"),
labels = c("Oracle G-Formula",
"Naive G-Formula",
"G-Formula CS")),
aa = factor(substr(method.aa, 8, 8)),
a = factor(a[aa]),
name = factor(substr(method.aa, 1, 3)),
EYa.true = EYa.true[aa]) %>%
dplyr::select(-method.aa) %>%
group_by(clust, n, B, vare, method, aa, a, name) %>%
mutate(id = row_number()) %>%
pivot_wider(names_from = name,
values_from = val,
id_cols = c(clust, n, B, vare, method, aa, a, EYa.true, id)) %>%
mutate(ci.lower = est - qnorm(0.975) * ste,
ci.upper = est + qnorm(0.975) * ste,
ci.cov = EYa.true >= ci.lower & EYa.true <= ci.upper,
bcci.lower = est - qnorm(0.975) * bcs,
bcci.upper = est + qnorm(0.975) * bcs,
bcci.cov = EYa.true >= bcci.lower & EYa.true <= bcci.upper)
# load simulation results from each of 10 clusters
sim.out.list <- lapply(
X = 0:9,
FUN = function(clust) {
cbind(clust,
read.csv(paste0("sim_data/gfmla_nonlinear_data/sd",
clust, ".csv")))
})
# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)
# true estimands
g <- c(0, 0.25, 0.5, -0.5, 1)          # outcome model parameters
a <- -1:2                                        # exposure value of interest
EYa.true <- g[1] + 0.5*g[5] + a*g[2] + a^2*g[3] + a^3*g[4]
# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare))
# make long data frame
sim.out.long <- sim.out %>%
pivot_longer(cols = starts_with("est") |
starts_with("ste") |
starts_with("bcs"),
names_to = "method.aa",
values_to = "val") %>%
mutate(method = factor(substr(method.aa, 5, 6),
levels = c("OG", "NG", "RG", "CG"),
labels = c("Oracle G-Formula",
"Naive G-Formula",
"Reg. Cal. G-Formula",
"Corrected G-Formula")),
aa = factor(substr(method.aa, 8, 8)),
a = factor(a[aa]),
name = factor(substr(method.aa, 1, 3)),
EYa.true = EYa.true[aa]) %>%
dplyr::select(-method.aa) %>%
group_by(clust, n, B, vare, method, aa, a, name) %>%
mutate(id = row_number()) %>%
pivot_wider(names_from = name,
values_from = val,
id_cols = c(clust, n, B, vare, method, aa, a, EYa.true, id)) %>%
mutate(ci.lower = est - qnorm(0.975) * ste,
ci.upper = est + qnorm(0.975) * ste,
ci.cov = EYa.true >= ci.lower & EYa.true <= ci.upper,
bcci.lower = est - qnorm(0.975) * bcs,
bcci.upper = est + qnorm(0.975) * bcs,
bcci.cov = EYa.true >= bcci.lower & EYa.true <= bcci.upper)
# summarize proportion of missing data by setting
ftc.dat <- sim.out.long %>%
filter(aa == 1) %>%
group_by(method, n, B, vare) %>%
summarise(prop.error = mean(is.na(est)))
ftc.dat %>%
filter(prop.error > 0) %>%
ungroup()
# extract simulation parameters
n <- unique(sim.out$n)
# make labels for plots
method.labs <- c("Oracle G-Formula",
"Naive G-Formula",
"Reg. Cal. G-Formula",
"G-Formula CS")
names(method.labs) <- c("OG", "NG", "RG", "CG")
n.labs <- paste0("n = ", n)
names(n.labs) <- n
a.labs <- paste0("a = ", a)
names(a.labs) <- a
# colorblind friendly pallette
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')
# separate plots for each exposure value a, and for selected methods
plot.by.a <- function(a., title = T) {
plot <- sim.out.long %>%
filter(a == a.) %>%
ggplot(aes(x = method,
y = est,
fill = method,
color = method)) +
geom_boxplot() +
geom_hline(aes(yintercept = EYa.true),
linetype = "dashed",
color = "orange") +
facet_wrap(~ n,
scales = "free",
labeller = labeller(n = n.labs)) +
labs(y = "Parameter Estimate",
fill = "Method",
color = "Method") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
legend.position = "bottom") +
scale_fill_manual(values = pal_light,
labels = method.labs) +
scale_color_manual(values = pal_dark,
labels = method.labs)
if (title) {
plot <- plot +
ggtitle(paste0("Empirical Distribution of Parameter Estimates"),
subtitle = paste0("a = ", a., "; ",
n.rep, " simulations per setting"))
}
return(plot)
}
plot.by.a(a. = -1)
plot.by.a(a. = 0)
plot.by.a(a. = 1)
plot.by.a(a. = 2)
rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(devtools)
load_all()
# load simulation results from each of 10 clusters
sim.out.list <- lapply(
X = 0:9,
FUN = function(clust) {
cbind(clust,
read.csv(paste0("sim_data/gfmla_nonlinear_2_data/sd",
clust, ".csv")))
})
# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)
# true estimands
g <- c(0, 0.25, 0.5, -0.5, 1)          # outcome model parameters
a <- seq(-1, 2, length = 20)           # exposure value of interest
EYa.true <- g[1] + 0.5*g[5] + a*g[2] + a^2*g[3] + a^3*g[4]
# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare))
# make long data frame
sim.out.long <- sim.out %>%
dplyr::select(!starts_with("a")) %>%
pivot_longer(cols = starts_with("OG") | starts_with("NG") | starts_with("CG"),
names_to = "method.aa",
values_to = "val") %>%
mutate(method = factor(substr(method.aa, 1, 2),
levels = c("OG", "NG", "CG"),
labels = c("Oracle G-Formula",
"Naive G-Formula",
"G-Formula CS")),
aa = as.numeric(gsub("[.]", "", substr(method.aa, 4, 5))),
a = a[aa],
EYa.true = EYa.true[aa]) %>%
dplyr::select(-method.aa)
# make summary data frame
sim.out.summary <- sim.out.long %>%
group_by(n, vare, B, method, a) %>%
summarise(bias = mean(val - EYa.true),
se = sd(val) / sqrt(n.rep),
bias.lower = bias - qnorm(0.975) * se,
bias.upper = bias + qnorm(0.975) * se)
View(sim.out)
