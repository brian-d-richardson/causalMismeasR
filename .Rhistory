rm(list = ls())
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggh4x)
library(kableExtra)
# load simulation results from each of 10 clusters
sim.out.list <- lapply(
X = 0:9,
FUN = function(clust) {
cbind(clust,
read.csv(paste0("sim_data/cme_ipw/sd",
clust, ".csv")))
})
# combine simulation results into 1 data frame
sim.out <- bind_rows(sim.out.list)
# true MSM parameters
g <- c(0.45, 0.20, 0.15, 0.15)
# number of sims per setting
n.rep <- nrow(sim.out) / n_distinct(dplyr::select(sim.out, n, B, vare))
# make long data frame
sim.out.long <- sim.out %>%
pivot_longer(cols = starts_with("ghat") | starts_with("stde"),
names_to = "method.param",
values_to = "val") %>%
mutate(method = factor(substr(method.param, 6, 7),
levels = c("OL", "OI",
"NL", "NI",
"CL", "CI")),
param = factor(substr(method.param, 9, 9)),
name = factor(substr(method.param, 1, 4)),
g.true = g[param]) %>%
dplyr::select(-method.param) %>%
group_by(clust, n, B, vare, method, param, name) %>%
mutate(id = row_number()) %>%
pivot_wider(names_from = name,
values_from = val,
id_cols = c(clust, n, B, vare, method,
param, g.true, id))
# summarize proportion of missing data by setting
sim.out.long %>%
filter(param == 1) %>%
group_by(method, n, B, vare) %>%
summarise(prop.error = mean(is.na(ghat))) %>%
filter(prop.error > 0) %>%
ungroup()
# extract simulation parameters
n <- unique(sim.out$n)
B <- unique(sim.out$B)
vare <- unique(sim.out$vare)
# make labels for plots
method.labs <- c("Oracle Linear",
"Naive Linear",
"Corrected Linear",
"Oracle IPW",
"Naive IPW",
"Corrected IPW")
names(method.labs) <- c("OL", "NL", "CL",
"OI", "NI", "CI")
n.labs <- paste0("n = ", n)
names(n.labs) <- n
B.labs <- paste0("B = ", B)
names(B.labs) <- B
vare.labs <- paste0("sigma_e = ", vare)
names(vare.labs) <- vare
param.labs <- paste0("\u03b3", c("\u2080", "\u2081", "\u2082", "\u2083"))
names(param.labs) <- 1:4
# colorblind friendly pallette
pal_light <- c('#EE6677', '#228833', '#4477AA', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB')
pal_dark <- c('#991122', '#114419', '#223b55', '#6b611d', '#117799', '#55193b', '#5d5d5d')
# separate plots for each sample size
plot.by.var <- function(vare. = 0.05, est_cutoff = Inf) {
ggplot(
data = filter(sim.out.long,
vare == vare.,
abs(ghat - g.true) < est_cutoff),
aes(x = method,
y = ghat,
fill = method,
color = method)) +
geom_boxplot() +
stat_summary(fun = mean,
geom = "point",
shape = 8,
size = 2,
orientation = "x",
show.legend = F) +
geom_hline(aes(yintercept = g.true),
linetype = "dashed",
color = "orange") +
facet_grid(n ~ param,
scales = "free",
labeller = labeller(n = n.labs,
param = param.labs)) +
labs(y = "Parameter Estimate",
fill = "Method",
color = "Method") +
ggtitle(paste0("Empirical Distribution of Parameter Estimates"),
subtitle = paste0(n.rep, " simulations per setting")) +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank()) +
scale_fill_manual(values = pal_light,
labels = method.labs) +
scale_color_manual(values = pal_dark,
labels = method.labs)
}
plot.by.var()
plot.by.var(est_cutoff = 1)
tbl <- sim.out.long %>%
group_by(param, method, n, B, vare) %>%
summarise(bias = mean(ghat - g.true, na.rm = T),
emp.se = sd(ghat, na.rm = T),
est.se = mean(stde)) %>%
gather(key, value, bias:est.se) %>%
unite(Group, param, key) %>%
spread(Group, value)
setNames(tbl, sub(".+_", "", names(tbl))) %>%
kable(digits = 3) %>%
kable_styling("striped") %>%
add_header_above(c(" " = 4,
"Component 1" = 3,
"Component 2" = 3,
"Component 3" = 3,
"Component 4" = 3))
plot.by.var()
View(sim.out)
seed = 9000090
library(MASS); library(devtools); load_all()
n = 800
B = 80
## define parameters
gg <- c(0.4, 0.15, 0.15, 0.2,
0.1, 0.1, 0, -0.1);                    # Y|A,L parameters
inv.link <- inv.ident;                         # MSM link function
d.inv.link <- d.inv.ident;                     # MSM derivative of link
var.e <- c(vare, vare, 0)                      # measurement error variance
coef.a.l <- matrix(
data = c(0, 0.4, 0, -0.4, 0.2, -0.1),        # coefs in A|L model
nrow = 3, byrow = T)
var.a.l <- c(0.09, 0.09, 0.09)                 # variance of A|L
## generate data
set.seed(seed)                                 # seed for reproducibility
L <- runif(n)                                  # confounder
A <- mvrnorm(n = n,                            # true exposure
mu = c(0, 0, 0),
Sigma = diag(var.a.l)) +
cbind(1, L) %*% t(coef.a.l)
Astar <- A + mvrnorm(n = n,                    # mismeasured exposure
m = c(0, 0, 0),
Sigma = diag(var.e))
Y_prob <- cbind(1, A, L, A*L) %*% gg           # mean of binary outcome
Y_prob[Y_prob < 0] <- 0                        # correct Y_prob in rare cases
Y_prob[Y_prob > 1] <- 1
Y <- rbinom(n, 1, Y_prob)                      # binary outcome
len.a <- ncol(A)                               # dimension of A
mean.a <- colMeans(A)                          # marginal mean of A
cov.a <- cov(A)                                # marginal covariance of A
# (i) oracle logistic regression
res.OL <- fit.glm(Y = Y, A = A, L = L,
inv.link = inv.link, d.inv.link = d.inv.link)
# (ii) naive logistic regression
res.NL <- fit.glm(Y = Y, A = Astar, L = L,
inv.link = inv.link, d.inv.link = d.inv.link)
# (iii) MCCS logistic regression
res.CL <- fit.glm.mccs(Y = Y, Astar = Astar, L = L, var.e = var.e,
inv.link = inv.link, d.inv.link = d.inv.link,
B = B, seed = 123)
# (iv) oracle IPW estimator
res.OI <- fit.ipw(Y = Y, A = A, L = L,
mean.a = mean.a, cov.a = cov.a,
inv.link = inv.link, d.inv.link = d.inv.link)
res.OI
# (iv) naive IPW estimator
res.NI <- fit.ipw(Y = Y, A = Astar, L = L,
mean.a = mean.a, cov.a = cov.a,
inv.link = inv.link, d.inv.link = d.inv.link)
# (vi) MCCS IPW estimator
res.CI <- fit.ipw.mccs(Y = Y, Astar = Astar, L = L,
var.e = var.e, B = B, seed = 123,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
inv.link = inv.link, d.inv.link = d.inv.link)
res.CI
x = res.OI$est
x
coef.a.l <- matrix(x[len.a + 1 + 1:(2 * len.a)], nrow = len.a, byrow = F)
var.a.l <- exp(x[3 * len.a + 1 + 1:len.a])
cbind(
get.psi.ipw.mccs(
Y = Y, Astar = Astar, L = L, g = x[1:((len.a) + 1)],
var.e = var.e, B = B, seed = 123,
inv.link = inv.link, d.inv.link = d.inv.link,
coef.a.l = coef.a.l,
var.a.l = var.a.l,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
return.sums = F),
get.psi.ps(
A = Astar, L = L,
coef.a.l = coef.a.l,
var.a.l = var.a.l + var.e,
return.sums = F)) }),
cbind(
get.psi.ipw.mccs(
Y = Y, Astar = Astar, L = L, g = x[1:((len.a) + 1)],
var.e = var.e, B = B, seed = 123,
inv.link = inv.link, d.inv.link = d.inv.link,
coef.a.l = coef.a.l,
var.a.l = var.a.l,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
return.sums = F),
get.psi.ps(
A = Astar, L = L,
coef.a.l = coef.a.l,
var.a.l = var.a.l + var.e,
return.sums = F)) })
cbind(
get.psi.ipw.mccs(
Y = Y, Astar = Astar, L = L, g = x[1:((len.a) + 1)],
var.e = var.e, B = B, seed = 123,
inv.link = inv.link, d.inv.link = d.inv.link,
coef.a.l = coef.a.l,
var.a.l = var.a.l,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
return.sums = F),
get.psi.ps(
A = Astar, L = L,
coef.a.l = coef.a.l,
var.a.l = var.a.l + var.e,
return.sums = F))
colMeans(          cbind(
get.psi.ipw.mccs(
Y = Y, Astar = Astar, L = L, g = x[1:((len.a) + 1)],
var.e = var.e, B = B, seed = 123,
inv.link = inv.link, d.inv.link = d.inv.link,
coef.a.l = coef.a.l,
var.a.l = var.a.l,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
return.sums = F),
get.psi.ps(
A = Astar, L = L,
coef.a.l = coef.a.l,
var.a.l = var.a.l + var.e,
return.sums = F))))
colMeans(          cbind(
get.psi.ipw.mccs(
Y = Y, Astar = Astar, L = L, g = x[1:((len.a) + 1)],
var.e = var.e, B = B, seed = 123,
inv.link = inv.link, d.inv.link = d.inv.link,
coef.a.l = coef.a.l,
var.a.l = var.a.l,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
return.sums = F),
get.psi.ps(
A = Astar, L = L,
coef.a.l = coef.a.l,
var.a.l = var.a.l + var.e,
return.sums = F)))
colSums(          cbind(
get.psi.ipw.mccs(
Y = Y, Astar = Astar, L = L, g = x[1:((len.a) + 1)],
var.e = var.e, B = B, seed = 123,
inv.link = inv.link, d.inv.link = d.inv.link,
coef.a.l = coef.a.l,
var.a.l = var.a.l,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
return.sums = F),
get.psi.ps(
A = Astar, L = L,
coef.a.l = coef.a.l,
var.a.l = var.a.l + var.e,
return.sums = F)))
set.seed(9000090
)
gg <- c(0.4, 0.15, 0.15, 0.2,
0.1, 0.1, 0, -0.1);                    # Y|A,L parameters
inv.link <- inv.ident;                         # MSM link function
d.inv.link <- d.inv.ident;                     # MSM derivative of link
var.e <- c(vare, vare, 0)                      # measurement error variance
coef.a.l <- matrix(
data = c(0, 0.4, 0, -0.4, 0.2, -0.1),        # coefs in A|L model
nrow = 3, byrow = T)
var.a.l <- c(0.09, 0.09, 0.09)                 # variance of A|L
## generate data
set.seed(seed)                                 # seed for reproducibility
L <- runif(n)                                  # confounder
A <- mvrnorm(n = n,                            # true exposure
mu = c(0, 0, 0),
Sigma = diag(var.a.l)) +
cbind(1, L) %*% t(coef.a.l)
Astar <- A + mvrnorm(n = n,                    # mismeasured exposure
m = c(0, 0, 0),
Sigma = diag(var.e))
Y_prob <- cbind(1, A, L, A*L) %*% gg           # mean of binary outcome
Y_prob[Y_prob < 0] <- 0                        # correct Y_prob in rare cases
Y_prob[Y_prob > 1] <- 1
Y <- rbinom(n, 1, Y_prob)                      # binary outcome
len.a <- ncol(A)                               # dimension of A
mean.a <- colMeans(A)                          # marginal mean of A
cov.a <- cov(A)                                # marginal covariance of A
seed = 123
start = NULL
len.a <- ncol(Astar)        # dimension of A
len.msm <- len.a + 1        # dimension of MSM parameters
len.ps <- 3 * len.a         # dimension of propensity score model parameters
n <- nrow(Astar)            # sample size
mean.a <- colMeans(Astar)
cov.a <- cov(Astar) - diag(var.e)
start <- rep(0, len.a + 1)
model.a.l <- lm(Astar ~ L)
coef.a.l <- t(coef(model.a.l))
var.a.l <- apply(model.a.l$residuals, 2, var) - var.e
# get naive estimates to use as starting values
root.naive <- fit.ipw(Y = Y, A = Astar, L = L,
inv.link = inv.link, d.inv.link = d.inv.link,
start = start, return.var = F)$est[1:len.msm]
root.naive
rootSolve::multiroot(
f = function(x) {
get.psi.ipw.mccs(
Y = Y, Astar = Astar, L = L, g = x,
var.e = var.e, B = B, seed = seed,
inv.link = inv.link, d.inv.link = d.inv.link,
coef.a.l = coef.a.l, var.a.l = var.a.l,
mean.a = mean.a, cov.a = cov.a) },
start = root.naive)
set.seed(9000090)
gg <- c(0.4, 0.15, 0.15, 0.2,
0.1, 0.1, 0, -0.1);                    # Y|A,L parameters
inv.link <- inv.ident;                         # MSM link function
d.inv.link <- d.inv.ident;                     # MSM derivative of link
var.e <- c(vare, vare, 0)                      # measurement error variance
coef.a.l <- matrix(
data = c(0, 0.4, 0, -0.4, 0.2, -0.1),        # coefs in A|L model
nrow = 3, byrow = T)
var.a.l <- c(0.09, 0.09, 0.09)                 # variance of A|L
## generate data
set.seed(seed)                                 # seed for reproducibility
L <- runif(n)                                  # confounder
A <- mvrnorm(n = n,                            # true exposure
mu = c(0, 0, 0),
Sigma = diag(var.a.l)) +
cbind(1, L) %*% t(coef.a.l)
Astar <- A + mvrnorm(n = n,                    # mismeasured exposure
m = c(0, 0, 0),
Sigma = diag(var.e))
Y_prob <- cbind(1, A, L, A*L) %*% gg           # mean of binary outcome
Y_prob[Y_prob < 0] <- 0                        # correct Y_prob in rare cases
Y_prob[Y_prob > 1] <- 1
Y <- rbinom(n, 1, Y_prob)                      # binary outcome
len.a <- ncol(A)                               # dimension of A
mean.a <- colMeans(A)                          # marginal mean of A
cov.a <- cov(A)                                # marginal covariance of A
# (vi) MCCS IPW estimator
res.CI <- fit.ipw.mccs(Y = Y, Astar = Astar, L = L,
var.e = var.e, B = B, seed = 123,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
inv.link = inv.link, d.inv.link = d.inv.link)
res.CI
library(rootSolve)
library(MASS)
library(mvtnorm)
library(tidyr)
source("R/estimating_functions.R")
setwd("C:/Users/Brian Richardson/OneDrive - University of North Carolina at Chapel Hill/Desktop/CFAR/Projects in Progress/Confounding and Measurement Error/mismex")
library(rootSolve)
library(MASS)
library(mvtnorm)
library(tidyr)
source("R/estimating_functions.R")
source("R/fit_equations.R")
source("R/link_functions.R")
source("R/misc_helpers.R")
source("R/sandwich_estimation.R")
source("R/simulation.R")
args = 9
base.seed <- 10^6 * as.integer(args)
# number of sims per cluster
n.sim <- 1
# varied parameters
n <- 800                          # sample size
B <- 80                           # number of MC replicates
vare <- 0.05                      # measurement error variance for A1, A2
# create simulation input
sim.in <- expand.grid(n = n,
B = B,
vare = vare,
sim.id = 1:n.sim + base.seed)
ii = 90
sim.in$sim.id[ii]
View(sim.in)
# number of sims per cluster
n.sim <- 100
# varied parameters
n <- 800                          # sample size
B <- 80                           # number of MC replicates
vare <- 0.05                      # measurement error variance for A1, A2
# create simulation input
sim.in <- expand.grid(n = n,
B = B,
vare = vare,
sim.id = 1:n.sim + base.seed)
sim.in$sim.id[ii]
# run simulations
sim.out <- pbapply::pbvapply(
X = 1:nrow(sim.in),
FUN = function(ii) {
sim1(n = sim.in$n[ii],
B = sim.in$B[ii],
vare = sim.in$vare[ii],
seed = sim.in$sim.id[ii])
},
FUN.VALUE = numeric(52)) |>
t()
sim.in$sim.id[ii]
sim1(n = sim.in$n[ii],
B = sim.in$B[ii],
vare = sim.in$vare[ii],
seed = sim.in$sim.id[ii])
sim.in$n[ii]
sim.in$B[ii]
n = sim.in$n[ii]
B = sim.in$B[ii]
vare = sim.in$vare[ii]
seed = sim.in$sim.id[ii]
## define parameters
gg <- c(0.4, 0.15, 0.15, 0.2,
0.1, 0.1, 0, -0.1);                    # Y|A,L parameters
inv.link <- inv.ident;                         # MSM link function
d.inv.link <- d.inv.ident;                     # MSM derivative of link
var.e <- c(vare, vare, 0)                      # measurement error variance
coef.a.l <- matrix(
data = c(0, 0.4, 0, -0.4, 0.2, -0.1),        # coefs in A|L model
nrow = 3, byrow = T)
var.a.l <- c(0.09, 0.09, 0.09)                 # variance of A|L
## generate data
set.seed(seed)                                 # seed for reproducibility
L <- runif(n)                                  # confounder
A <- mvrnorm(n = n,                            # true exposure
mu = c(0, 0, 0),
Sigma = diag(var.a.l)) +
cbind(1, L) %*% t(coef.a.l)
Astar <- A + mvrnorm(n = n,                    # mismeasured exposure
m = c(0, 0, 0),
Sigma = diag(var.e))
Y_prob <- cbind(1, A, L, A*L) %*% gg           # mean of binary outcome
Y_prob[Y_prob < 0] <- 0                        # correct Y_prob in rare cases
Y_prob[Y_prob > 1] <- 1
Y <- rbinom(n, 1, Y_prob)                      # binary outcome
len.a <- ncol(A)                               # dimension of A
mean.a <- colMeans(A)                          # marginal mean of A
cov.a <- cov(A)                                # marginal covariance of A
# (vi) MCCS IPW estimator
res.CI <- fit.ipw.mccs(Y = Y, Astar = Astar, L = L,
var.e = var.e, B = B, seed = 123,
mean.a = mean(Astar), cov.a = cov(Astar) - diag(var.e),
inv.link = inv.link, d.inv.link = d.inv.link)
res.CI
mean(Astar)
colMeans(Astar)
